{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#tag:other","title":"Other","text":"<ul> <li>            Cellular Backup          </li> <li>            Tape Backup          </li> <li>            ZFS Send/Receive          </li> <li>            Zfshost          </li> </ul>"},{"location":"Other/cellular_backup/","title":"Cellular Backup","text":"<p>I spend quite a bit of time away from home and I do have a few somewhat critical services running in my homelab that I would like to be able to access 24/7 remotely. At a minimum, being able to remote into my main workstation allows me to travel light with just a chromebook. Therefore I try to have as many redundancies as feasibly possible, including the following:</p> <ul> <li>UPSes for servers, switches, APs, router and modem</li> <li>PiKVM for servers and OPNsense router</li> <li>ZFS mirror on OPNsense with UEFI bootloader on both drives</li> <li>ZFS with parity on main server with ZFSBootMenu bootloader on 2 separate drives (one USB and one SD card)</li> </ul> <p>The above list provides decent protection against power loss and disk failures. However, I needed a redundancy for my home internet connection, which was the weakest link. I wanted to add a way to get into my LAN remotely when my cable connection was down to access devices or data and potentially fix any networking issues to bring the cable internet connection back up.</p>","tags":["Other"]},{"location":"Other/cellular_backup/#goals","title":"Goals","text":"<ul> <li>Have a dedicated device on the LAN that will serve as entry point into LAN</li> <li>Use a Google Fi data SIM (metered at $10/GB) (need to minimize usage)</li> <li>Failover to LTE only when main WAN is down</li> <li>Switch back to main WAN as soon as it's back up</li> <li>Run punch out services to better handle IP changes due to interface change</li> </ul>","tags":["Other"]},{"location":"Other/cellular_backup/#plan","title":"Plan","text":"<ul> <li>Check for WAN connectivity via <code>ping -I eth0</code> (requires the interface to be up, even when not connected to ISP)<ul> <li>Can't disable interface when there is no ISP connection, because then the connectivity check cannot be done</li> <li>Rely on <code>metric</code> instead. Increase when no connectivity, decrease again when connected</li> </ul> </li> <li>Perform a connectivity check every minute on cron</li> <li>Check against 4 different public servers (Google, Cloudflare and Quad9 dns servers)</li> <li>If all 4 pings fail, increase eth0 metric to above cellular, making cellular connection the default</li> <li>If any of the 4 pings succeed, decrease eth0 metric to make it active again</li> <li>Notify and log on connection changes</li> <li>Run Tailscale and Cloudflared to make it easier to enter (both services auto update public IP)</li> </ul>","tags":["Other"]},{"location":"Other/cellular_backup/#hardware","title":"Hardware","text":"<p>I picked up a USB 4G LTE modem, ZTE MF833V, for about $40. It's a category 4 device, which means it can support speeds up to 150/50Mbps. That's plenty for a backup connection mainly for remoting in when the cable internet is down.</p> <p>I dedicated an older Raspberry Pi 3 to act as the gateway.</p>","tags":["Other"]},{"location":"Other/cellular_backup/#software","title":"Software","text":"<p>On the rpi3, I decided to go with Ubuntu Server 24.04 running off of an SD card.</p> <p>The USB modem should be auto detected by the kernel, but it needs some initial configuration to set up the networking type, NAT and APN settings. Mine came with Windows software to do that and I used a Windows VM. Unfortunately I don't remember the details. But once it was set up, plugging into a linux device lets it connect to the LTE network and get an IP.</p> <p>Mine is set to run DHCP in the range of <code>192.168.0.0/24</code>.</p> <p>When plugged into the rpi3 with Ubuntu 24.04, the modem is detected and the interface is created, but it is not up. I had to use the following netplan config to accomplish 2 things: 1. Set default metric and a static IP for the LAN interface (eth0) 2. Bring up the cellular interface (usb0) with default metric and a static IP</p> <p><code>/etc/netplan/90-usb-modem.yaml</code>: <pre><code>network:\n    ethernets:\n        eth0:\n            dhcp4: false\n            addresses:\n              - 192.168.1.20/24\n            routes:\n              - to: default\n                via: 192.168.1.1\n                metric: 100\n            nameservers:\n                addresses: [192.168.1.1]\n        usb0:\n            dhcp4: false\n            optional: true\n            addresses: [192.168.0.184/24]\n            routes:\n              - to: 0.0.0.0/0\n                via: 192.168.0.1\n                metric: 1000\n    version: 2\n</code></pre></p> <p>eth0 part overrides the default dhcp config / usb0 part enables the USB LTE modem and creates its interface</p> <p>The following script checks for online connectivity by pinging 4 dns servers and if they all fail, it switches the metric of eth0 (100 &gt; 2000) to make usb0 the default. When eth0 connectivity is back, it lowers eth0 metric (2000 &gt; 100) to make it default.</p> <p><code>/home/aptalca/failover.sh</code>: <pre><code>#!/bin/bash\n\nfn_notify () {\n  curl -Lfs -H \"Title: $1\" -H \"Authorization: Bearer &lt;my token&gt;\" -d \"$2\"  https://ntfy.&lt;mydomain&gt;/zfshost || \\\n    curl -Ls -H \"Title: $1\" -d \"$2\" https://ntfy.sh/&lt;my custom topic&gt;\n}\n\nif ! ping -c 1 -W 5 -I eth0 8.8.4.4; then\n  if ! ping -c 1 -W 5 -I eth0 8.8.8.8; then\n    if ! ping -c 1 -W 5 -I eth0 1.1.1.1; then\n      if ! ping -c 1 -W 5 -I eth0 9.9.9.9; then\n        if ip route | grep -q \"default via 192.168.1.1 dev eth0 proto static metric 100\"; then\n          ip route del default via 192.168.1.1 dev eth0 proto static metric 100\n          ip route add default via 192.168.1.1 dev eth0 proto static metric 2000\n          TZ=America/New_York echo \"$(date) connection down, deprioritizing eth0\" &gt;&gt; /home/aptalca/eth0-status.log\n          chown 1000:1000 /home/aptalca/eth0-status.log\n          sleep 3\n          fn_notify \"Pifi eth0 down\" \"Pifi connection down, deprioritizing eth0\"\n        fi\n        exit 0\n      fi\n    fi\n  fi\nfi\n\nif ip route | grep -q \"default via 192.168.1.1 dev eth0 proto static metric 2000\"; then\n  ip route del default via 192.168.1.1 dev eth0 proto static metric 2000\n  ip route add default via 192.168.1.1 dev eth0 proto static metric 100\n  TZ=America/New_York echo \"$(date) connection back up, prioritizing eth0\" &gt;&gt; /home/aptalca/eth0-status.log\n  chown 1000:1000 /home/aptalca/eth0-status.log\n  sleep 3\n  fn_notify \"Pifi eth0 back up\" \"Pifi connection back up, prioritizing eth0\"\nfi\n</code></pre></p> <p>Set up a root crontab to run the script every minute</p> <p><code>sudo crontab -e</code></p> <p><code>* * * * * /home/aptalca/failover.sh</code></p> <p>I also installed Tailscale and Cloudflared. Tailscale allows ssh access into my LAN. Cloudflared allows me to serve the PiKVM interface over a Cloudflare tunnel. Both services punch out and automatically update the public IP so I can connect whether WAN is up or down.</p> <p>When WAN is active, which is the great majority of the time, there is no data transfer over cellular so I keep the metered data cost at an absolute minimum.</p>","tags":["Other"]},{"location":"Other/cellular_backup/#update","title":"Update","text":"<p>After over a year of successfully and reliably working, one day out of the blue, it stopped. We had a big power outage when I was away from home. The script successfully changed the metric of <code>eth0</code> from 100 to 2000, which would have made the <code>usb0</code> interface the active default. But that didn't happen. When the power came back and I was able to ssh in to my lan, I saw that there was no <code>usb0</code> interface (facepalm).</p> <p><code>lsusb</code> listed the usb modem, but there was no interface. After a lengthy troubleshooting session, going down several rabbit holes, I had another facepalm moment when I realized the interface was indeed created, but it was now named <code>eth1</code> (sigh) and obviously down since the netplan config tries to enable an interface named <code>usb0</code>. <code>dmesg</code> output confirmed the finding:</p> <pre><code>usb 1-1.3: New USB device found, idVendor=19d2, idProduct=1405, bcdDevice=54.18\nusb 1-1.3: New USB device strings: Mfr=1, Product=2, SerialNumber=3\nusb 1-1.3: Product: ZTE Mobile Broadband\nusb 1-1.3: Manufacturer: ZTE,Incorporated\ncdc_ether 1-1.3:1.0 eth1: register 'cdc_ether' at usb-0000:01:00.0-1.3, ZTE CDC Ethernet Device, xx:xx:xx:xx:xx:xx\nusbcore: registered new interface driver cdc_ether\n</code></pre> <p>Somehow (maybe a kernel update?? or maybe udev??) the behavior changed and <code>cdc_ether</code> now creates the interface with the <code>eth</code> prefix instead of <code>usb</code>. I'm not happy with this situtation as it completely broke my backup internet (it had one job).</p> <p>So I thought, no big deal, I'll create a udev rule to set a static interface name by mac address. Unfortunately, the mac address gets randomly assigned on connect/boot and changes every time (facepalm #3).</p> <p>Instead, I settled on using the usb bus id to set the following udev rule: <pre><code>$ cat /etc/udev/rules.d/10-custom-cel0.rules \nKERNELS==\"1-1.3:1.0\", NAME=\"cel0\"\n</code></pre></p> <p>Then I modified the netplan config to enable the new interface <code>cel0</code> instead of the previous <code>usb0</code>.</p> <p><code>dmesg</code> output confirms the interface rename: <pre><code>cdc_ether 1-1.3:1.0 eth1: register 'cdc_ether' at usb-0000:01:00.0-1.3, ZTE CDC Ethernet Device, xx:xx:xx:xx:xx:xx\nusbcore: registered new interface driver cdc_ether\ncdc_ether 1-1.3:1.0 cel0: renamed from eth1\n</code></pre></p> <p>Since this is a dedicated device that I never touch, I'll just make sure to leave the usb modem connected to the same port and hope that the ids don't change in the future, rendering the udev rule useless.</p>","tags":["Other"]},{"location":"Other/tape_backup/","title":"Tape Backup","text":"<p>A few months ago, I picked up a used LTO-6 internal tape drive on eBay for $300. Admittedly, it was an impulse buy. I also gambled because the seller listed it with no guarantees but a simple statement <code>pulled from a working server</code>. Luckily the gamble paid off and I received a working unit.</p> <p>The reasons I looked for a tape drive in the first place were that one, I had always been curious about the tech, and two, I recently downsized my homelab significantly. Reducing storage capacity meant I would have to *gasp* delete some of my meticulously curated (not hoarded, mind you) media. I figured I could perhaps write them to tape drives so they weren't forever lost.</p> <p>There was quite a steep learning curve and some challenges with regards to both the hardware and the software aspects of this tech. In this article, I'll chronicle my journey.</p>","tags":["Other"]},{"location":"Other/tape_backup/#background","title":"Background","text":"<p>For over a decade, I relied on a main server that was built inside of a 4U rack case with three 5-in-3 hot swap cages. Initially it had a Supermicro X9SCA-F board with an Intel Xeon E5-2670v1. I'm frugal budget conscious when it comes to electronics and I got the CPU used, which I believe was pulled from a server at a Facebook data center. Coming from a super cheap but single core AMD Sempron 145 (later unlocked to dual core Athlon II X2 4450e... whee!), it was a tremendous upgrade. It transformed my basic NAS into a proper server that could handle multiple VMs with GPU passthrough and many docker containers. I had a dozen HDDs and multiple GPUs in there. It was a lot of fun messing around with it and I certainly had the time then. Learned a ton in the process.</p> <p>Over the years, the board and the CPU got upgraded to a more modern Supermicro X11SCA-F and Intel Xeon E-2146G, and the HDDs went from a mix of 1-3TB drives to mostly 8TB drives (most of them shucked from external drives of course).</p> <p>At some point I added a backup server with a budget Pentium G4600 in a midsize tower with decommissioned 1-3TB HDDs.</p> <p>Fast forward to a few months ago, my needs and circumstances completely changed. We are about to move to a house with no basement, so keeping these big and noisy servers in a basement, out of sight and mind, is no longer an option. I had to consolidate and downsize everything in my homelab. Low power and low noise became an important factor.</p> <p>For the main server, I opted for a tiny but relatively powerful server with an Intel N305 CPU in a Jonsbo N2 case. I detailed that server in this article.</p> <p>For the backup server, I built something with almost all spare parts that I had lying around in my homelab (curated, not hoarded). It turned into a real Frankenstein's Monster of a server. I had to get pretty creative and feel real proud of the outcome. I will outline that below.</p>","tags":["Other"]},{"location":"Other/tape_backup/#hardware","title":"Hardware","text":"<p>First of all, this backup server was not pre-planned in any way, shape or form. It is a result of a series of <code>oh, I should figure out a way to connect X device</code> and <code>oh wait, I do have this component in the closet</code> types of thoughts and evolved into its current form.</p> <p>Behold the Frankenstein's Monster aka Ghettolab:</p> <p></p> <p></p> <ol> <li>Tape Drive: Dell LTO-6 internal SAS drive. Main motivation for building the backup server. I really wanted to be able to use this thing that I had just acquired. But since downsizing the main server as well as the router, I had no devices I could attach this thing to. Because it's SAS, it needs an HBA, which needs a pci-e port. I was not able to find a SAS-USB adapter at a reasonable cost. It also needs SATA power, more power than a HDD, which needed a PSU.</li> <li>HBA: Tape drive needs an HBA that supports SAS and I had an older Dell Perc 200 that was decommissioned along with my old main server. The new server (Zfshost) only supports 5 HDDs and it has a built in backplane. Now I had to find a motherboard to hook up the HBA to.</li> <li>Motherboard: ZimaBoard. I had this ZimaBoard for a few years. It's a very cool device because while it's tiny, it has a pci-e slot on the side (Gen2 x4). It served as my OPNsense router in the last couple of years, but I recently decommissioned it because with 2 SSDs and an Intel pci-e card, all hanging out, it looked too fragile (not a quality I want in a router). I replaced it with an N150 box with 4 Intel 2.5G ports, with an M2 NVME and an SSD, all internal, which looks a lot sturdier. So the Zima was a perfect choice for hosting the HBA and the tape drive.</li> <li>PSU: I initally hooked up a decommissioned 750W PSU, which was overkill for the setup and was huge. Now I had a mess on my hands. ZimaBoard connected to HBA, connected to tape drive, connected to PSU, all hanging out and too fragile (not to mention ugly). Then I remembered this old case I had that happened to have a 5.25 inch slot I never used. It also had a built-in PSU (nothing fancy, but enough for the tape drive and a couple of drives). So I scrapped the separate PSU idea in favor of the case with the built-in PSU.</li> <li>Case: An old case I had from 2008 where it served as my first HTPC case. This thing sat under my TV and served my movies and TV shows through initially Meedio, then XBMC for years. Before I built a NAS, this thing had multiple external HDDs attached to it and was starting to look like Medusa. After building a NAS and switching to an even smaller HTPC for the living room, this case moved to the basement and was connected to my 3D 1080p projector and surround sound system (man cave). After getting replaced again, this time by a FireTV, it became my router, first on PfSense and later on OPNsense, with an added low profile dual nic gigabit Intel pci-e card. Finally in 2023, it was replaced by a Zimaboard with a dual nic Intel pci-e card (this time 2.5G). Since then it was sitting in a closet, looking sad. So many memories. It became the perfect housing for this Monster, thanks to its built-in PSU and the 5.25 inch drive slot. I took out the old motherboard and insterted the ZimaBoard along with the HBA (held in place by velcro fastener).</li> <li>Drives: Now that I got a backup server with a tape drive set up, I figured I could pop in a larger HDD to hold some ZFS snapshots. So I went with a decommissioned 250GB SSD as the OS drive, and I put in a decommissioned 6TB HDD with ZFS as the data drive. It has no mirroring or parity yet (I only had one 6TB drive and there wasn't any room in the case for another anyway). But that's OK as this is strictly a backup server anyway (Insert Rocky IV gif <code>If he dies, he dies</code>).</li> <li>Cabling: This is where I had to get creative. Things were pretty cramped in there. Due to cables not reaching, I initially had to connect the SSD to the HBA. However that caused a lot of issues because booting from an older HBA is finnicky. My HBA (or its firmware) didn't support UEFI. Legacy booting for some reason didn't work with Debian Bookworm. At first I used ZimaBoard's internal eMMC hosted CasaOS's grub to boot into Debian on SSD, but then I got some extenders and connected both drives directly to the ZimaBoard for data, but put them on the PSU instead of powering from the ZimaBoard (it is not recommended to have the ZimaBoard power an HDD and an SSD at the same time).</li> </ol> <p>I'm pretty proud of the outcome. I now have a low power and quiet backup server with 6TB of storage and a tape drive, in a nice little sturdy bundle and best of all, it didn't cost me anything extra apart from the $3 SATA power extender cable.</p>","tags":["Other"]},{"location":"Other/tape_backup/#software","title":"Software","text":"<p>I put Debian Bookworm on the SSD. Formatted ext4, nothing fancy. The 6TB HDD holds a ZFS pool so it can receive ZFS snapshots from the main server. It only has 3 services running on there as docker containers: 1. Beszel Agent: Server monitoring. Not nearly as customizable or featureful as a Grafana stack, but much much easier to set up and maintain. 2. AdGuard-Home: Backup instance in case the main server is down for maintenance. Set up on mobile devices as the second DNS. 3. Tape: My custom docker container built for using a tape drive, complete with screen, cron and backup scripts.</p> <p>ZFS receive functionality is thoroughly detailed in this linked article so I won't get into that here.</p> <p>This section will focus mainly on the tape drive functionality via my custom docker container.</p> <p>Most tape drives should be automatically detected by a recent kernel and various devices should be created (ie. <code>/dev/stX</code> and <code>/dev/nstX</code>). Interfacing with these devices can be accomplished via the <code>mt-st</code> package that provides the <code>mt</code> command. However, keep in mind that the <code>mt</code> command provides raw access to the blocks on tape and by default there is no filesystem. You can put a filesystem on there, as there is a foss option called LTFS, but given how tapes are best used for sequential reading and writing, and they're very slow at seeking, LTFS provides low performance compared to other modern storage options. I played with it a little bit, and decided against it.</p>","tags":["Other"]},{"location":"Other/tape_backup/#tape-drive-general-facts","title":"Tape Drive General Facts","text":"<ul> <li>Tapes are good for about 30 years, which makes them a great long term storage option. They are also not very expensive especially considering the long lifetime.</li> <li>Tape drives are for sequential reading and writing. Each tar file is written and appended with an <code>EOF</code> marker that defines the end of the file.</li> <li>Tape drives can easily and relatively quickly identify the EOF markers to determine the beginning and end of each file.</li> <li>Writing and reading operations always begin on where the drive head currently is. Pay close attention to that prior to each operation.</li> <li><code>/dev/st0</code> is a rewinding device. After each operation, the tape is rewound to the beginning. <code>/dev/nst0</code> is non-rewinding and the head remains at its location at the end of each operation.</li> <li>To move the tape drive head, <code>mt</code> command is used. To read or write, <code>tar</code> is used (fun fact: tar acronym stands for <code>tape archive</code>).</li> <li><code>mt -f /dev/nst0 status</code> will show the status of the drive head. If it's at a file (vs a block), it will list the <code>File number</code>. If it's at the beginning of a file, it will list <code>EOF</code> at the bottom (except for the first file, which is really called <code>File number=0</code>, which will show <code>BOT</code> indicating the <code>beginning of tape</code>).</li> <li>You can seek to the beginning via <code>mt -f /dev/nst0 rewind</code> or <code>mt -f /dev/nst0 asf 0</code></li> <li>You can seek to the beginning of any file via <code>mt -f /dev/nst0 asf X</code>with <code>X</code> being the file number (starting from <code>0</code>)</li> <li>You can seek to the end of tape via <code>mt -f /dev/nst0 eod</code></li> <li>From the end, you can seek to the beginning of the last file via <code>mt -f /dev/nst0 bsfm 2</code></li> </ul>","tags":["Other"]},{"location":"Other/tape_backup/#writing-to-tape","title":"Writing To Tape","text":"<ul> <li>For the first write, make sure to rewind via <code>mt -f /dev/nst0 rewind</code> and confirm with <code>status</code>.</li> <li>With tar, you can write directly to the tape via <code>tar -cvf /dev/nst0 sourcedirectory1 sourcedirectory2</code>.</li> <li>If you used the non-rewinding <code>nst0</code> device, the drive head should be at the beginning of the second file, indicated by <code>File number=1</code> and <code>EOF</code> in <code>status</code> output.</li> <li>To write the second file, make sure the <code>status</code> shows <code>File number=1</code> and <code>EOF</code>.</li> <li>Same command, <code>tar -cvf /dev/nst0 sourcedirectory1 sourcedirectory2</code>, will now write the second tar file and the head should move to <code>File number=2</code>.</li> <li>If you overwrite the first file, all subsequent files will be lost. Pay attention to where the head is before each write operation. You can use <code>mt</code> to forward to the end of the tape to be sure.</li> <li>For long operations run manually via cli, you can use <code>screen</code> so you don't have to keep a shell open.</li> </ul>","tags":["Other"]},{"location":"Other/tape_backup/#reading-from-tape","title":"Reading From Tape","text":"<ul> <li>You can seek to the beginning of files with the command <code>mt -f /dev/nst0 asf X</code> with X being the file number (starting with 0).</li> <li>To copy the first file from tape to the current folder on the local machine, rewind via <code>mt -f /dev/nst0 rewind</code> (or via <code>mt -f /dev/nst0 asf 0</code>).</li> <li>Use the tar command to extract from tape: <code>tar -xvf /dev/nst0</code>. It will read the first file all the way to the EOF, and extract it to the local disk.</li> <li>To copy the second file from tape, seek to it via <code>mt -f /dev/nst0 asf 1</code> and extract via <code>tar -xvf /dev/nst0</code>.</li> <li>For long operations run manually via cli, you can use <code>screen</code> so you don't have to keep a shell open.</li> </ul>","tags":["Other"]},{"location":"Other/tape_backup/#important-notice","title":"Important Notice","text":"<p>Never do <code>mt -f /dev/nst0 erase</code> unless you know it's really what you want. The manpage is not clear about it, but it actually does a <code>secure erase</code>, it takes a really long time (8+ hrs) and you can't cancel it once started. Killing or force killing the process doesn't work, <code>docker stop</code> and <code>docker kill</code> fail. The only way is to cut the power to the drive, which could damage the drive head.</p>","tags":["Other"]},{"location":"Other/tape_backup/#fully-automated-incremental-tape-backups","title":"Fully Automated Incremental Tape Backups","text":"<p>I realize larger organizations often rely on tape libraries with autoloaders and proprietary software solutions to manage their backups. Unfortunately I do not have those luxuries in my humble homelab.</p> <p>I wanted a simple (KISS) solution for backing up different source folders to different tapes, in an incremental manner without user input (other than switching tapes). My time is limited and precious. I also wanted it to be foolproof so that I couldn't mess it up if I wanted to. I'm often doing homelab projects in a rush so my manual tasks are prone to typos and errors.</p> <p>So I came up with a sample script included in this linked repo.</p> <p>It basically does incremental backups to tape. However, the source directories (along with some optional custom tar arguments) as well as the last tar snapshot file are saved on tape so that whenever you switch the tape out, the script automatically retrieves these from the tape itself to figure it all out. My motivation for this last step was borne out of the fact that my backup server does not have any built-in redundancies (remember the Rocky IV quote from earlier). If it dies, I didn't want to lose any data related to the tape backups so I made sure all tape backup related data was also stored on the tapes themselves, so that all future incremental backups and restores can be performed with access to just the tape itself.</p> <p>All you do is stick a pre-initialized tape into the drive, and run the script (manually or via cron). The script also helps you initialize a tape.</p> <p>You can have one tape that backs up your computer backup folders. Another tape that backs up your family photos. Or perhaps a second tape for your family photos for good measure, but with different increments. It's easy. Just stick a tape into the drive and run the script. It will automagically figure out the source folders, custom tar arguments and the last snapshot state; and it will write a new incremental tar to tape.</p>","tags":["Other"]},{"location":"Other/tape_backup/#setting-up-the-tape-container","title":"Setting Up The Tape Container:","text":"<pre><code>  tape:\n    image: ghcr.io/aptalca/tape\n    container_name: tape\n    volumes:\n      - /home/aptalca/appdata/tape:/config\n      - /mnt:/mnt\n    environment:\n      PUID: 1000\n      PGID: 1000\n      TZ: America/New_York\n    devices:\n      - /dev/st0:/dev/st0\n      - /dev/nst0:/dev/nst0\n    cpus: 3\n    mem_limit: 5g\n    restart: unless-stopped\n</code></pre> <p>Just save the above yaml as <code>docker-compose.yml</code> and do <code>docker compose up -d</code> and you'll have a working tape container with all the necessary tools inside.</p>","tags":["Other"]},{"location":"Other/tape_backup/#how-to-initialize-a-tape","title":"How To Initialize A Tape","text":"<ol> <li>Exec into the running container and run the init script: <code>docker exec -it tape /config/tape.sh init</code></li> <li>Enter the necessary information requested.</li> <li>You can include tar arguments as part of the directories. For instance, I don't like to include the full path of my backed up folders so I set a base folder and then define a folder inside to be backed up, ie. <code>-C /mnt/pool/Pictures All</code>. When you restore that backup, it will result in the extracted folder as <code>All</code> and not <code>mnt/pool/Pictures/All</code>.</li> </ol> <p>Now you should have a tape initialized with <code>file 0</code> containing the tarball of your source directories and <code>file 1</code> containing the tar snapshot and the directories.txt file. When the backup script is run, it will first retrieve these index files, use them to generate a new incremental tar and write the pair to tape.</p>","tags":["Other"]},{"location":"Other/tape_backup/#how-to-do-an-incremental-backup","title":"How To Do An Incremental Backup:","text":"<ol> <li>Run this script manually (<code>screen docker exec -it tape /config/tape.sh</code>) or via cron with no arguments (<code>7 5 * * 0 /config/tape.sh &gt;&gt; /config/logs/log.txt 2&gt;&amp;1 &amp;&amp; chown abc:abc /config/logs/log.txt</code>)</li> </ol> <p>It will seek to the end of tape, and then move to the beginning of the last file written. It will read the last backup's state info and the directories to create a diff. It will seek to the beginning of the next file, write the incremental tar, then it will move to the next file again and write the latest state file and the directories.</p>","tags":["Other"]},{"location":"Other/tape_backup/#how-to-do-a-restore","title":"How To Do A Restore:","text":"<ol> <li>Exec into the running container and run the restore script: <code>docker exec -it tape /config/tape.sh restore</code></li> <li>Enter the necessary information requested</li> </ol> <p>Once the base folder is selected (defaults to <code>/config</code>), it will rewind the tape and extract every single tar file from tape into the base folder.</p>","tags":["Other"]},{"location":"Other/tape_backup/#my-current-workflow","title":"My Current Workflow","text":"<p>My most valuable data is my family photos and videos. I dedicated two tapes to that. I usually keep one of those in the tape drive and on cron, it does weekly incremental backups. Every couple of weeks, I switch it out for the other one. That's all the maintenance it takes.</p> <p>I also have a couple of other tapes for miscellaneous data I acquired over the years. Some work documents, some computer backups, etc. Those don't change that much. When they do, I stick the tape in, run a manual incremental backup through screen, and switch it back to one of the family photos tapes. It's very much a set it and forget it type of workflow. I also tested restores and they worked beautifully.</p> <p>With this, I am pretty confident about mitigating data loss. My main server has ZFS with dual parity and plenty of snapshots. Backup server receives zfs snapshots from the main and stores them. Crucial data is written to tape regularly. Plus I upload to Backblaze B2, which provides the offsite storage. I feel anything more would be overkill (I hope I'm not wrong about this).</p>","tags":["Other"]},{"location":"Other/tape_backup/#misconception-that-bit-me-in-the-a","title":"Misconception That Bit Me In The A$$","text":"<p>In the opening statement, I wrote that one of the main reasons for looking into tape drives was that I was downsizing my storage capacity and that I would like to write some of my data to tape instead of deleting it forever. Well, that assumption was based on a bold faced lie by the <code>Big Tape</code>. You see, when they talk about the specs of LTO-6, they list the tape capacity as 6.25TB compressed and they'll have a little footnote that shows 2.5TB uncompressed.</p> <p>I mistakenly assumed that the <code>compressed</code> part was similar to how the 3.5 inch floppy disks went from having 720KB space to 1.44MB by simply writing at a higher density to the same size disk back in the late 80s and early 90s. I even remember drilling holes in my existing 720KB disks to have them detected as high density disks so I could double the space (it wasn't recommended for crucial data but they mainly held my Amiga games at the time so all was well, but I digress).</p> <p>Unfortunately in this case, <code>compressed</code> literally means compressed (lossless) like zip, gzip and the like. It turns out, these drives have built in hardware acceleration for a lossless compression algorithm that they utilize when writing to and reading from tape. This is completely invisible to the user. Sure, if you're writing a ton of text files, the drive will be able to compress it greatly and it will take up much less space on tape. So they came up with some theoretical (made up) average compression ratio of <code>2.5:1</code> so they can inflate the advertised storage capacity to 6.25TB.</p> <p>However, in this day and age, most data I'm writing to tape is already heavily compressed (think JPG, MP4, etc.) and therefore whatever algorith the drive utilizes is unable to compress them any further. So in my tests, I quickly realized that the actual storage capacity was much much closer to the uncompressed 2.5TB (I exaggarate, it was practically equal to 2.5TB).</p> <p>This fact threw a wrench in my whole plan to preserve my carefully curated media archive as I realized I would need two and a half times the number of tapes than I originally had planned for. That number (I'm embarrased to spell it out) was not feasible in terms of both cost and physical storage space. Sadly, I had to delete my carefully curated media archive forever. Thanks <code>Big Tape</code>.</p> <p>But at least I learned a lot about the tape tech and ended up with a pretty cool and effortless additional backup method.</p>","tags":["Other"]},{"location":"Other/zfs_send_receive/","title":"ZFS Send/Receive","text":"<p><code>zfs send</code> from main server and <code>zfs receive</code> on backup server</p>","tags":["Other"]},{"location":"Other/zfs_send_receive/#general-facts-for-consideration","title":"General Facts For Consideration","text":"<ol> <li>Both <code>zfs send</code> and <code>zfs receive</code> operations require plenty of permissions, which can be assigned to an unprivileged user via <code>zfs allow</code> (we should not run the script as root on either end as most guides suggest)</li> <li>If the source dataset is auto-mounted, it will be attempted to be mounted on the receiving end, which can be a problem</li> <li>If a backup dataset is mounted, there is a possibility (highly likely if <code>atime</code> is on) that it will be modified on the receiving end, semi-breaking future incremental updates</li> <li>For scripted operations, one would need to have an ssh key without passphrase on either the main or the backup server, for the other one.</li> <li>Unlike rsync, which compares source and destination data for diff calculation, <code>zfs send</code> only compares 2 snapshots on the source end to calculate diff, meaning the source and destination must contain a common snapshot, which should be used as the base of the diff on the sending end</li> <li>All properties of the source dataset will be set on the backup dataset as is, which means any property that is <code>inherited</code> on the source will also be set as <code>inherited</code> on the backup, so the actual value may differ (such as the mountpoint)</li> <li>If the machine with the ssh key gets compromised, the other machine is also compromised due to no ssh key passphrase</li> <li>If the source machine gets compromised (ransomwared), the changes can propagate to backups</li> <li>If <code>zfs allow</code> has the <code>destroy</code> permission, a compromised machine can potentially destroy all zfs data including the pools, datasets and the snapshots.</li> <li>Initial <code>send</code> requires that the destination does not have the existing dataset (you can force but I'd rather keep it clean and simple)</li> <li>Incremental <code>send</code> requires the destination state matches the base snapshot used in <code>send</code></li> </ol>","tags":["Other"]},{"location":"Other/zfs_send_receive/#plan","title":"Plan","text":"<ul> <li>Due to <code>1.</code> and <code>4.</code> above, we will use a dedicated unprivileged linux user <code>zfsbackup</code> (not in sudoers) on both the sending and the receiving ends<ul> <li>On the sending end, the user will need the <code>zfs allow</code> perms <code>create,mount,rename,send,snapshot</code> (<code>create</code> and <code>mount</code> are there because they are required by others) (we do not assign the <code>destroy</code> perm due to <code>9.</code>)</li> <li>On the receiving end, the user will need the <code>zfs allow</code> perms <code>atime,canmount,create,mount,readonly,receive,rename</code> (<code>create</code> and <code>mount</code> are there because they are required by others) (we do not assign the <code>destroy</code> perm due to <code>9.</code>)</li> <li>Allow perms are per user per dataset and are inherited. Existing perms can be checked via <code>zfs allow &lt;pool&gt;/&lt;dataset&gt;</code></li> </ul> </li> <li>To prevent issues due to <code>2.</code> and <code>3.</code>, we will use the options <code>-o canmount=noauto -u -o readonly=on</code> because the first 2 will prevent mounting on the receiving end and the 3rd will prevent modifications (for good measure).<ul> <li>We can also add <code>-o atime=off</code> if we do want to mount them, but if it's read only, that should not be necessary.</li> <li>These options are overridden permanently on the receiving end. If we ever have to recover from these backups, we need to kee in mind that our backup datasets have altered properties, which may need to be reverted after a restore. It is prudent to keep these alterations to a minimum so a potential restore doesn't get too complicated.</li> </ul> </li> <li>Picking the receiving end as the initator and holder of the ssh key with no passphrase because that machine is a dedicated backup machine, has no public facing services and thus less likely to be compromised.</li> <li>On the receiving end, we create a new encrypted dataset dedicated to holding backups <code>pool/remotebackups</code> and set the options <code>readonly:on</code> and <code>canmount=noauto</code>. Keep in mind that while the <code>readonly</code> setting is inherited, the <code>canmount</code> setting is not.</li> <li>Because we have multiple pools on the source machine (one for the OS on NVMEs and one for the data/media on HDDs), we'll replicate the same structure on the receiving end to make things simpler:<ul> <li><code>zarray/Books</code> on the source will be backed up to <code>pool/remotebackups/zarray/Books</code> on the receiving end</li> <li><code>zroot/ROOT/debian</code> on the source will be backed up to <code>pool/remotebackups/zroot/ROOT/debian</code> on the receiving end</li> </ul> </li> <li>Since we have to specifically define the source snapshot on the sending end during incremental, and that snapshot state has to match the current state of the backup dataset, we will hardcode snapshot names and make assumptions based on that<ul> <li>We could label the snapshot with date stamps that would match on the sending and the receiving ends, but that would require parsing zfs list outputs and/or keeping a file or db with previous run info. That complicates things and is error prone (hardcoding the snapshot names makes it safer for a cron script to delete them as we reduce the risk of accidentally deleting the wrong snapshot or worse, a dataset)</li> <li>It's much simpler to rely on the following format for snapshot names:<ul> <li><code>remotebackup-snapshot</code> for the snapshot that will be sent and received</li> <li><code>remotebackup-snapshot-1</code> for the snapshot that will be used as the diff base</li> </ul> </li> <li>Prior to send, we rename the snapshots <code>remotebackup-snapshot</code> as <code>remotebackup-snapshot-1</code> on both ends, create a new snapshot <code>remotebackup-snapshot</code> on the sending end, and send that with the diff base <code>remotebackup-snapshot-1</code></li> <li>At the end of the send operation, both ends will have the matching snapshots <code>remotebackup-snapshot</code> and <code>remotebackup-snapshot-1</code></li> <li>Nightly, we have to delete the <code>remotebackup-snapshot-1</code> snapshots on both ends but that has to be done by a privileged user like root cron, otherwise the rename will fail due to existing snapshot with that name</li> <li>At the start of each send operation, we will have only the <code>remotebackup-snapshot</code> on both ends</li> <li>If the structure and naming of the snapshots gets messed up due to errors when running the script, we'll have the script notify us so we can take manual action</li> </ul> </li> </ul>","tags":["Other"]},{"location":"Other/zfs_send_receive/#specific-steps","title":"Specific Steps","text":"","tags":["Other"]},{"location":"Other/zfs_send_receive/#initial-sync","title":"Initial sync","text":"<ol> <li>Let's assume we're syncing <code>zarray/Books</code> on main machine to <code>pool/remotebackups/zarray/Books</code> on the backup machine</li> <li>Add permissions to source dataset on main machine: <code>sudo zfs allow zfsbackup create,mount,rename,send,snapshot zarray/Books</code></li> <li>Create the parent pool/dataset on the backup machine: <code>sudo zfs create -o canmount=noauto -o readonly=on pool/remotebackups/zarray</code></li> <li>Add permissions to backup parent pool/dataset on backup machine: <code>sudo zfs allow zfsbackup atime,canmount,create,mount,readonly,receive,rename pool/remotebackups/zarray</code></li> <li>Log into <code>zfsbackup</code> on the backup machine: <code>su zfsbackup</code></li> <li>Create snapshot on the source dataset via ssh: <code>ssh zfsbackup@MAINSERVERIP zfs snapshot zarray/Books@remotebackup-snapshot</code></li> <li>Perform initial sync via ssh: <code>ssh zfsbackup@MAINSERVERIP zfs send -v zarray/Books@remotebackup-snapshot | zfs receive -o canmount=noauto -u -o readonly=true pool/remotebackups/zarray/Books</code></li> </ol>","tags":["Other"]},{"location":"Other/zfs_send_receive/#subsequent-incremental-sync","title":"Subsequent Incremental Sync","text":"<ol> <li>Log into <code>zfsbackup</code> on the backup machine: <code>su zfsbackup</code></li> <li>Rotate snapshot on the source dataset via ssh: <code>ssh zfsbackup@MAINSERVERIP zfs rename zarray/Books@remotebackup-snapshot zarray/Books@remotebackup-snapshot-1</code></li> <li>Create new snapshot on the source dataset via ssh: <code>ssh zfsbackup@MAINSERVERIP zfs snapshot zarray/Books@remotebackup-snapshot</code></li> <li>Rotate snapshot on the backup dataset: <code>zfs rename pool/remotebackups/zarray/Books@remotebackup-snapshot pool/remotebackups/zarray/Books@remotebackup-snapshot-1</code></li> <li>Perform incremental sync via ssh: <code>ssh zfsbackup@MAINSERVERIP zfs send -vi zarray/Books@remotebackup-snapshot-1 zarray/Books@remotebackup-snapshot | zfs receive -o canmount=noauto -u -o readonly=true pool/remotebackups/zarray/Books</code></li> </ol>","tags":["Other"]},{"location":"Other/zfs_send_receive/#clean-up-after-sync","title":"Clean Up After Sync","text":"<ol> <li>On the main machine edit the root crontab via <code>sudo crontab -e</code> and add an entry to delete the rotated snapshot: <code>17 0 * * * zfs destroy zarray/Books@remotebackup-snapshot-1</code></li> <li>On the backup machine edit the root crontab via <code>sudo crontab -e</code> and add an entry to delete the rotated snapshot: <code>17 0 * * * zfs destroy pool/remotebackups/zarray/Books@remotebackup-snapshot-1</code></li> </ol>","tags":["Other"]},{"location":"Other/zfs_send_receive/#my-ugly-script","title":"My Ugly Script","text":"<pre><code>#!/bin/bash\n\n# Edit the below values\n\n# Set Source Datasets\nSOURCEDATASETS='zarray/Books zarray/Misc zroot/home zroot/ROOT/debian'\n# Set Local Backup Base\nBACKUPBASE='pool/remotebackups'\n# Set remote server\nREMOTESERVER='zfsbackup@&lt;SERVERIP&gt;'\n\n# notify via self hosted server or if that fails, via the public instance\nfn_notify () {\n  curl -Lfs -H \"Title: $1\" -H \"Authorization: Bearer &lt;my token&gt;\" -d \"$2\"  https://ntfy.&lt;mydomain&gt;/zfshost || \\\n    curl -Ls -H \"Title: $1\" -d \"$2\" https://ntfy.sh/&lt;my custom topic&gt;\n}\n\n# Do not make edits below this line\n\necho \"**** Starting sync on $(date)\"\n# Check to make sure remote server is up and connectable\nif ssh -o ConnectTimeout=10 \"${REMOTESERVER}\" true; then\n  echo \"[Success] Remote server is up and connectable\"\nelse\n  echo \"[Failed] Remote server does not seem to be reachable. Aborting zfs sync.\"\n  fn_notify \"Zima Zfs Sync Failed\" \"Remote server does not seem to be reachable. Aborting zfs sync.\"\n  exit 1\nfi\n\nfor SRC in ${SOURCEDATASETS}; do\n  echo \"**********************************\"\n  echo \"**********************************\"\n  echo \"**** Processing dataset ${SRC}\"\n  # check to make sure the latest snapshot exists on local\n  if zfs list -t snapshot \"${BACKUPBASE}/${SRC}\" | grep -q \"@remotebackup-snapshot \"; then\n    echo \"[Success] ${BACKUPBASE}/${SRC}@remotebackup-snapshot exists on local as expected\"\n  else\n    echo \"[Failed] ${BACKUPBASE}/${SRC}@remotebackup-snapshot does not exist on local. Skipping backup of ${SRC}\"\n    fn_notify \"Zima Zfs Sync Failure\" \"${BACKUPBASE}/${SRC}@remotebackup-snapshot does not exist on local. Skipping backup of ${SRC}\"\n    continue\n  fi\n  # check to make sure the renamed snapshot does not exist on local\n  if ! zfs list -t snapshot \"${BACKUPBASE}/${SRC}\" | grep -q \"@remotebackup-snapshot-1 \"; then\n    echo \"[Success] ${BACKUPBASE}/${SRC}@remotebackup-snapshot-1 does not exist on local as expected\"\n  else\n    echo \"[Failed] ${BACKUPBASE}/${SRC}@remotebackup-snapshot-1 already exists on local. Skipping backup of ${SRC}\"\n    fn_notify \"Zima Zfs Sync Failure\" \"${BACKUPBASE}/${SRC}@remotebackup-snapshot-1 already exists on local. Skipping backup of ${SRC}\"\n    continue\n  fi\n  # check to make sure the latest snapshot exists on remote\n  if ssh \"${REMOTESERVER}\" \"zfs list -t snapshot ${SRC} | grep -q \\\"@remotebackup-snapshot \\\"\"; then\n    echo \"[Success] ${SRC}@remotebackup-snapshot exists on remote as expected\"\n  else\n    echo \"[Failed] ${SRC}@remotebackup-snapshot does not exist on remote. Skipping backup of ${SRC}\"\n    fn_notify \"Zima Zfs Sync Failure\" \"${SRC}@remotebackup-snapshot does not exist on remote. Skipping backup of ${SRC}\"\n    continue\n  fi\n  # check to make sure the renamed snapshot does not exist\n  if ! ssh \"${REMOTESERVER}\" \"zfs list -t snapshot ${SRC} | grep -q \\\"@remotebackup-snapshot-1 \\\"\"; then\n    echo \"[Success] ${SRC}@remotebackup-snapshot-1 does not exist on remote as expected\"\n  else\n    echo \"[Failed] ${SRC}@remotebackup-snapshot-1 already exists on remote. Skipping backup of ${SRC}\"\n    fn_notify \"Zima Zfs Sync Failure\" \"${SRC}@remotebackup-snapshot-1 already exists on remote. Skipping backup of ${SRC}\"\n    continue\n  fi\n  # Rename snapshots on both local and remote\n  echo \"Renaming snapshot on the local\"\n  zfs rename \"${BACKUPBASE}/${SRC}@remotebackup-snapshot\" \"${BACKUPBASE}/${SRC}@remotebackup-snapshot-1\"\n  if [ \"$?\" -ne 0 ]; then\n    echo \"[Failed] Renaming snapshot on the local failed. Skipping backup of $SRC\"\n    fn_notify \"Zima Zfs Sync Failure\" \"Renaming snapshot on the local failed. Skipping backup of $SRC\"\n    continue\n  fi\n  echo \"Renaming snapshot on the remote\"\n  ssh \"${REMOTESERVER}\" \"zfs rename ${SRC}@remotebackup-snapshot ${SRC}@remotebackup-snapshot-1\"\n  if [ \"$?\" -ne 0 ]; then\n    echo \"[Failed] Renaming snapshot on the remote failed. Skipping backup of $SRC\"\n    fn_notify \"Zima Zfs Sync Failure\" \"Renaming snapshot on the remote failed. Skipping backup of ${SRC}\"\n    continue\n  fi\n  # create snapshot on remote\n  echo \"Creating snapshot on the remote\"\n  ssh \"${REMOTESERVER}\" \"zfs snapshot ${SRC}@remotebackup-snapshot\"\n  if [ \"$?\" -ne 0 ]; then\n    echo \"[Failed] Creating snapshot on the remote failed. Skipping backup of $SRC\"\n    fn_notify \"Zima Zfs Sync Failure\" \"Creating snapshot on the remote failed. Skipping backup of ${SRC}\"\n    continue\n  fi\n  # Initiate zfs send\n  echo \"Initiating zfs send for ${SRC}\"\n  ssh \"${REMOTESERVER}\" \"zfs send -vi ${SRC}@remotebackup-snapshot-1 ${SRC}@remotebackup-snapshot\" | zfs receive -o readonly=on -o canmount=noauto -u \"${BACKUPBASE}/${SRC}\"\n  if [ \"$?\" -ne 0 ]; then\n    echo \"[Failed] Sending snapshot failed. Skipping backup of $SRC\"\n    fn_notify \"Zima Zfs Sync Failure\" \"Sending snapshot failed. Skipping backup of ${SRC}\"\n    continue\n  fi\n  SRC_COMPLETED=\"${SRC} ${SRC_COMPLETED}\"\n  echo \"[Success] Zfs send for ${SRC} completed\"\n  echo \"**********************************\"\n  echo \"**********************************\"\n  echo \"**********************************\"\ndone\nif [ -n \"${SRC_COMPLETED}\" ]; then\n  fn_notify \"Zima Zfs Sync Completed\" \"The following datasets were successfully synced: ${SRC_COMPLETED}\"\nfi\necho \"Ended sync on $(date)\"\n</code></pre> <p>This script is not pretty, has plenty of duplicate commands and statements. I prefer function over form. My primary goals with this script are error detection and verbosity. Because I rely on hardcoded snapshot names, and because zfs send receive needs the snapshots perfectly synced on both sides, I really want to make sure I preserve the snapshots. Otherwise, incremental sync will break and I'll need to do a full sync again. If anything goes wrong, this script will immediately halt, log the error and notify via ntfy so I can go in and fix it manually.</p> <p>I have this script set to run weekly via the <code>zfsbackup</code> user's cron on the backup machine. I also have the root cron scripts running nightly to delete the rotated snapshots (named <code>@remotebackup-snapshot-1</code>) for each source and backup dataset on both machines.</p>","tags":["Other"]},{"location":"Other/zfshost/","title":"Zfshost","text":"<p>Details of my new mini homelab server</p>","tags":["Other"]},{"location":"Other/zfshost/#hardware","title":"Hardware","text":"<ul> <li>Jonsbo N2 case</li> <li>Purple CWWK/Topton board with i3-N305 processor and Jonsbo CPU fan (2 eth instead of 4, pci-e port has its own lane so it can be used alongside both M2 ports)</li> <li>Corsair 48GB mem stick (4800 version)</li> <li>2 1TB WD Blue Nvme on the board M2 slots (1X each unfortunately so not full speed) in a ZFS mirrored pool for the OS</li> <li>5 8TB WD (mostly red) HDD in drive bays in a ZFS RAIDZ2 pool (24TB usable) for long term storage</li> <li>1 256GB SSD (haven't decided what to use it for yet, probably temp files like <code>/var/lib/docker</code> content to increase the life of NVMEs)</li> <li>750W Thermaltake SFX PSU</li> <li>Coral dual tpu in a pci-e adapter</li> <li>PiKVM ATX controller (hooked up to motherboard header pins)</li> <li>USB header splitter and adapter to connect the case's USB A and USB C ports to the motherboard's single USB 3 header port (I'm honestly surprised this system worked because plenty of folks online said it wouldn't)<ul> <li>USB 3 header splitter</li> <li>USB 3 to type C header adapter</li> </ul> </li> <li>6 in 1 SATA cable (case is very cramped and full SATA cables make ot more crowded in there)</li> <li>1 32GB sdcard as UEFI #1 with ZfsBootMenu</li> <li>1 32GB USB flash drive (in mobo USB slot) as UEFI #2 with ZfsBootMenu (for redundancy)</li> <li>APC UPS connected to a USB2 port in the back</li> </ul>","tags":["Other"]},{"location":"Other/zfshost/#software","title":"Software","text":"","tags":["Other"]},{"location":"Other/zfshost/#uefi","title":"UEFI","text":"<p>Custom build of ZfsBootMenu on 2 separate devices (1 sdcard and 1 USB stick for redundancy). Used the container build method but added Tailscale and NTFY.</p> <p>ZfsBootMenu waits for passphrase and once entered, unlocks all zfs pools, searches for bootable datasets, provides them as options (for optional multi-boot). It also allows for zfs recovery and snapshot management. It also caches the ZFS keys when launching the OS so pools/datasets can be mounted automatically.</p> <p>Custom build includes: - Tailscale (for remote access) - Dropbear (for remote access) - Notifications via Discord and NTFY (so that when it boots after a power failure, I'm notified to ssh in and enter the ZFS unlock passphrase to minimize down time)</p> <p>Tip: When setting up your network access in ZfsBootMenu with a static IP, use the interface name <code>eth0</code> or <code>eth1</code> because that's what the VoidLinux based ZfsBootMenu uses instead of the more modern <code>enpXsX</code> scheme. For instance if your Debian install lists two network interfaces <code>enp4s0</code> and <code>enp5s0</code>, ZBM will identify them as <code>eth0</code> and <code>eth1</code> respectively.</p> <p>Here's my tree for the zfsbootmenu build folder: <pre><code>/etc/zfsbootmenu\n\u251c\u2500\u2500 build                               - Output folder for built EFIs. Always keeps one older version named backup by default.\n\u2502   \u251c\u2500\u2500 zfsbootmenu-backup.EFI            I do \"cp -a /etc/zfsbootmenu/build/zfsbootmenu.EFI /boot/efi/EFI/BOOT/BOOTX64.EFI\" to\n\u2502   \u2514\u2500\u2500 zfsbootmenu.EFI                   update the EFI on the mounted sd card (and USB flash drive mounted to \"/boot/efi2\")\n\u251c\u2500\u2500 cleanup.d\n\u2502   \u2514\u2500\u2500 hostfiles                       - Cleans up temp files at the end of build\n\u251c\u2500\u2500 config.yaml                         - Enables initcpio and other settings for the build\n\u251c\u2500\u2500 dropbear                            - Contains the dropbear config and keys\n\u2502   \u251c\u2500\u2500 dropbear.conf                   - Contains the listen port argument\n\u2502   \u251c\u2500\u2500 dropbear_ecdsa_host_key         - Host keys don't need to exist as they would be created on first run, then they would be reused\n\u2502   \u251c\u2500\u2500 dropbear_ecdsa_host_key.pub\n\u2502   \u251c\u2500\u2500 dropbear_ed25519_host_key\n\u2502   \u251c\u2500\u2500 dropbear_ed25519_host_key.pub\n\u2502   \u251c\u2500\u2500 dropbear_rsa_host_key\n\u2502   \u251c\u2500\u2500 dropbear_rsa_host_key.pub\n\u2502   \u2514\u2500\u2500 root_key                        - Contains my public ssh key for key based ssh login\n\u251c\u2500\u2500 initcpio\n\u2502   \u251c\u2500\u2500 hooks                           - Contains runtime hooks for when ZfsBootMenu loads\n\u2502   \u2502   \u251c\u2500\u2500 ntfy                        - Sends notification with a 10 sec delay (also has a discord notification added)\n\u2502   \u2502   \u251c\u2500\u2500 dropbear                    - Starts the dropbear service\n\u2502   \u2502   \u251c\u2500\u2500 rclocal                     - Sets up networking\n\u2502   \u2502   \u2514\u2500\u2500 tailscale                   - Starts the tailscale service\n\u2502   \u251c\u2500\u2500 install                         - Contains build time hooks for building ZfsBootMenu\n\u2502   \u2502   \u251c\u2500\u2500 ntfy                        - Copies the ca-certificates into UEFI for curl ssl and enables the runtime hook\n\u2502   \u2502   \u251c\u2500\u2500 dropbear                    - Creates host keys if needed, copies the keys and dropbear binary into UEFI, and enables the runtime hook\n\u2502   \u2502   \u251c\u2500\u2500 rclocal                     - Enables the runtime hooks that enable networking for ZfsBootMenu\n\u2502   \u2502   \u2514\u2500\u2500 tailscale                   - Copies the tailscale and dep binaries and the state file into UEFI, and enables the runtime hook\n\u2502   \u2514\u2500\u2500 rc.local                        - Contains the networking config (interface, routes and dns)\n\u251c\u2500\u2500 mkinitcpio.conf.d                   - Contains the conf files for initcpio modules (hooks and binaries) needed to be installed/enabled in ZfsBootMenu\n\u2502   \u251c\u2500\u2500 ntfy.conf                       - Adds the curl binary and enables ntfy hooks\n\u2502   \u251c\u2500\u2500 dropbear.conf                   - Enables dropbear hooks\n\u2502   \u251c\u2500\u2500 network.conf                    - Enables the rclocal hooks for networking\n\u2502   \u2514\u2500\u2500 tailscale.conf                  - Enables the tailscale hooks and adds the ip and dhclient binaries\n\u251c\u2500\u2500 rc.d                                - Contains scripts to prepare the build container environment\n\u2502   \u251c\u2500\u2500 dropbear                        - Copies the dropbear config files into the build container filesystem\n\u2502   \u2514\u2500\u2500 tailscale                       - Copies the tailscale config files into the build container filesystem\n\u251c\u2500\u2500 tailscale                           - Contains the tailscale config and state files\n\u2502   \u251c\u2500\u2500 tailscaled.conf\n\u2502   \u2514\u2500\u2500 tailscaled.state\n\u251c\u2500\u2500 zbm-builder.conf                    - Config for the zbm builder\n\u2514\u2500\u2500 zbm-builder.sh                      - Script that builds the ZfsBootMenu UEFI in a docker container and outputs to build folder\n\n10 directories, 31 files\n</code></pre> With all config files in place, simply cd to the folder and run <code>zbm-builder.sh</code> from inside that folder. It creates a docker build container with the current folder mounted, and it will use the various rc.d and mkinitcpio init files to prepare the build environment, build the UEFI image, and output to <code>build/</code>. You can then copy it to your boot drive at <code>/EFI/BOOT/BOOTX64.EFI</code>.</p>","tags":["Other"]},{"location":"Other/zfshost/#os","title":"OS","text":"<p>Debian (Bookworm) server installed on the dual NVME mirrored ZFS pool. Protected by ZFS passphrase (key also stored in the pool for caching and automounting). Install followed ZfsBootMenu instructions: https://docs.zfsbootmenu.org/en/latest/guides/debian/bookworm-uefi.html with a few changes: - Followed the <code>Separate Boot Device</code> instructions but skipped the parts about creating a partition on the NVME for the ZFS pool (because I'm using a separate device for the UEFI). I instead created the ZFS pool using the full disk. - Created an encrypted pool. - Instructions make you use a single disk for the pool. Afterwards I converted it to a dual mirror by adding the second NVME to the pool.</p> <p>Tip: Stock Debian server does not come with any ntp client/service installed so eventually time shifts and operations involving time based cryptography start failing. Don't forget to install the ntp package (or alternative) to keep time synced. I found out through Authelia crashing on start.</p> <p>When I first set up stock Debian, I noticed some startup log errors about the GPU. I also noticed that hw transcode wasn't working in containers when passing the DRI device. Researching the issue, I became aware of two potential causes. Unfortunately, I applied both fixes at once so I can't tell for sure now if both are necessary or if one would suffice. But I personally would have eventually implemented both of these for other reasons anyway: - Upgraded the kernel to the backports version because I thought my gpu was too new for the stock Debian kernel for full support. That may or may not be true, but I needed the newer kernel for other reasons as well so I'm keeping it. - Added <code>non-free-firmware</code> to Debian apt sources (<code>/etc/apt/sources.list</code>) so the Intel drivers/firmware are upgraded.</p> <p>Upgrading the kernel lead to another issue, this time with the Coral pci-e driver for the Edge TPU. Apparently, Google sucks at keeping the driver up to date. Following their official directions results in an error during compilation. After some rabbit hole exploring, I came across an unmerged PR that solves the issue with compiling on the 6.12 kernel: https://github.com/google/gasket-driver/pull/35 I had to locally build the DKMS deb with that patch and install it.</p>","tags":["Other"]},{"location":"Other/zfshost/#zfs","title":"ZFS","text":"","tags":["Other"]},{"location":"Other/zfshost/#zfs-pools","title":"ZFS Pools","text":"<p>OS pool was created above. I then created an encrypted ZFS pool made up of the 5 8TB HDDs in RAIDZ2 (2 parity) for a usable space of 24TB. When creating, make sure to use the devices <code>/dev/disk/by-id</code> instead of <code>/dev/sdX</code>. <code>lsblk</code> is your friend.</p> <p>Resources: - https://docs.zfsbootmenu.org/en/latest/guides/debian/bookworm-uefi.html#create-the-zpool - https://virtualize.link/Other/zfs/#creation</p>","tags":["Other"]},{"location":"Other/zfshost/#zfs-dataset-structure","title":"ZFS Dataset Structure","text":"<p>My home folder is on its own dataset <code>zroot/ROOT/home</code> and it contains all my docker app data (persistent data) at <code>/home/aptalca/appdata</code>.</p> <p><code>/var/lib/docker</code> is on its own dataset <code>zroot/docker</code> along with my openvscode-server's dind docker folder and the <code>modcache</code> as all of that is ephemeral and I can set the least aggressive snapshot plan for it.</p> <p>My long term storage pool (HDD based) <code>zarray</code> has datasets for <code>Media</code>, <code>Books</code>, <code>Pictures</code> and <code>Misc</code> (contains backups and other miscellanous data).</p>","tags":["Other"]},{"location":"Other/zfshost/#zfs-auto-mount","title":"ZFS Auto Mount","text":"<p>Unfortunately Debian's ZFS package no longer auto mounts pools and datasets. Apparently it was disabled due to a bug that affected some people a while back.</p> <p>To enable, follow the instructions here (essentially do <code>sudo systemctl edit zfs-mount</code> and add the missing <code>-l</code> to the <code>zfs mount</code> command so it loads the cached keys when attempting the mount).</p> <p>To make sure the key for the HDD pool is cached by ZfsBootMenu, make sure to add the property <code>org.zfsbootmenu:keysource</code> to the pool. If using the same passphrase as the OS pool (highly recommended), you'd set it to <code>org.zfsbootmenu:keysource=\"zroot/ROOT/debian\"</code> along with <code>keylocation=file:///etc/zfs/zroot.key</code> and <code>keyformat=passphrase</code>. That way ZfsBootMenu will know to unlock and mount the OS pool first, and cache the key in <code>/etc/zfs/zroot.key</code> for both pools.</p>","tags":["Other"]},{"location":"Other/zfshost/#zfs-snapshots","title":"ZFS Snapshots","text":"<p>The auto-snapshot package is highly recommended. By default it does frequent (every 15 minutes), hourly, daily, weekly and monthly snapshots on all pools and datasets. The behavior can be customized by setting properties in pools and datasets.</p> <p>I have disabled daily, weekly and monthly on the OS dataset (<code>zroot/ROOT/debian</code>). I also moved <code>/var/lib/docker</code> out of the OS dataset into a newly created <code>zroot/docker</code> dataset as it's all ephemeral data and did not need to mingle it with the rest of the OS.</p>","tags":["Other"]},{"location":"Other/zfshost/#zfs-alerts","title":"ZFS Alerts","text":"<p>By default the zfs package on Debian enables monthly ZFS scrubs. The alerts are managed by ZED, which can be customized to send notifications via various methods.</p> <p>I enabled NTFY via instructions here and emails via msmtp (no mta package installed, just the <code>/etc/mail.rc</code> edited with the content <code>set sendmail=/usr/bin/msmtp</code> and <code>ZED_EMAIL_PROG=\"mail\"</code> set in <code>zed.rc</code>.</p> <p>I enabled both for redundancy. I use my own self hosted NTFY server and there are brief instances where it may not be accessible. In that case, email notification is a good backup.</p>","tags":["Other"]},{"location":"Other/zfshost/#apc-ups","title":"APC UPS","text":"<p>Set up apcupsd with instructions here.</p> <p>I created a custom scripts folder at <code>/etc/apcupsd/customscripts</code> and copied all the scripts into that folder to prevent the scripts from getting overwritten during a package update.</p> <p>In <code>/etc/apcupsd/apcupsd.conf</code>, I set <code>SCRIPTDIR /etc/apcupsd/customscripts</code>.</p> <p>In <code>/etc/apcupsd/customscripts/apccontrol</code> I set <code>SCRIPTDIR=/etc/apcupsd/customscripts</code></p> <p>And I modified the scripts <code>onbattery</code>, <code>offbattery</code> and <code>doshutdown</code> to add email and NTFY notifications. As an example, my <code>onbattery</code> script contains the following: <pre><code>printf \"To: myemail@gmail.com\\nFrom: Zfshost &lt;myemail@gmail.com&gt;\\nSubject: Power loss at home\\n\\nPower went out at home on %s\\n\\n%s\" \"$(/usr/bin/date)\" \"$(/sbin/apcaccess status)\" | /usr/bin/msmtp --auth=on --tls=on --host smtp.gmail.com --port 587 --user myemail@gmail.com --read-envelope-from --read-recipients --password 'echo &lt;gmail app password&gt;' --logfile /home/aptalca/msmtp.log\nchown 1000:1000 /home/aptalca/msmtp.log\ncurl -fs \\\n  -H \"Authorization: Bearer &lt;my_token&gt;\" \\\n  -d \"Power went out at home on $(date)\" \\\n  https://ntfy.&lt;mydomain&gt;/zfshost || \\\ncurl \\\n  -d \"Power went out at home on $(date)\" \\\n  https://ntfy.sh/&lt;mycustomtopic&gt;\nexit 0\n</code></pre> So it first sends me an email, then sends me an NTFY notification through my self hosted instance. If that fails, it notifies me through the public instance of NTFY (which is less reliable as its notifications aren't totally instant, but it has better uptime than my self hosted instance, therefore it's a decent backup).</p> <p>I get notified when the power goes out, when the power comes back (if within the DELAY period set) and when the server decides to shut down.</p>","tags":["Other"]},{"location":"Other/zfshost/#smart-alerts","title":"SMART Alerts","text":"<p>Installed the smartmontools package and modified the <code>/etc/smartmontools/smartd.conf</code> to enable both email alerts (via msmtp) and via NTFY.</p> <p>It performs automatic tests and monitors disk tempreature. Notifies if there are any issues.</p>","tags":["Other"]},{"location":"Other/zfshost/#docker","title":"Docker","text":"<p>Installed docker from the official repos: https://docs.docker.com/engine/install/debian/</p> <p>Put the <code>/var/lib/docker</code> contents into the ZFS dataset <code>zroot/docker</code> mounted to <code>/mnt/docker</code> by adding <code>\"data-root\": \"/mnt/docker/docker\"</code> into <code>/etc/docker/daemon.json</code> so I could disable the auto snapshots. Currently debating whether to move that to the SSD instead (the one connected to the 6th SATA port on the mobo and not added to any ZFS pools).</p> <p>I also put the modmanager data (<code>/mnt/docker/modmanager</code>) as well as the <code>/var/lib/docker</code> content of my <code>openvscode-server</code>'s DIND (<code>/mnt/docker/dind-openvscode-server</code>) in that same dataset. None of those 3 sources of data need to be retained and can easily be recreated by running the containers again.</p> <p>The persistent data of all containers reside under <code>/home/aptalca/appdata</code>. The home folder is on its own ZFS dataset with an aggressive snapshot schedule as that data is crucial. Compose yamls (one for Immich specifically and one for all others) are at <code>/home/aptalca</code>.</p> <p>Keeping most container arguments in a single yaml results in a very long file. I took advantage of yaml anchors described here to make it more manageable.</p>","tags":["Other"]},{"location":"Other/zfshost/#docker-networking-and-macvlan","title":"Docker Networking and Macvlan","text":"<p>We generally recommend against using macvlan for docker containers however there are a few use cases where macvlans are necessary. One use case is when we want to manage container traffic via source IP based firewall rules on the router (Opnsense). I have a few containers that I do that for, such as bypassing VPN to upload backups to Backblaze B2, or putting certain containers on a different VPN that supports port forwarding (for . . . reasons).</p> <p>One major drawback of macvlan is that devices or containers on a macvlan can't access or be accessed by the host that is not on the macvlan. That is a kernel restriction not specific to docker, but an annoying issue. To get around it, you can create a virtual interface and route the connections through there as the kernel restriction affects the main interface only.</p> <p>What I did is, create the following custom interface config and place it in <code>/etc/network/interfaces.d/</code>, which not only sets up my server ethernet with a static IP, but it also creates a virtual interface along with a route for it that has a lower metric (higher priority) than the main interface so all lan connections go over the virtual interface. That way, macvlan containers can connect the host and vice versa.</p> <pre><code>    auto lan1\n    iface lan1 inet static\n        address 192.168.1.50/24\n        gateway 192.168.1.1\n\n    auto lan1.10\n    iface lan1.10 inet manual\n\n    post-up ip link add vhost0 link lan1 type macvlan mode bridge\n    post-up ip link set vhost0 up\n    post-up ip route add 192.168.1.0/24 dev lan1 proto kernel scope link src 192.168.1.50 metric 1\n    post-up ip route del 192.168.1.0/24 dev lan1 proto kernel scope link src 192.168.1.50\n    post-up ip route add 192.168.1.0/24 dev vhost0 proto kernel scope link src 192.168.1.50\n    post-up ip link add vhost0.10 link lan1.10 type macvlan mode bridge\n    post-up ip link set vhost0.10 up\n</code></pre> <p><code>lan1</code> is my main ethernet interface and <code>lan1.10</code> is the <code>vlan 10</code> tagged version. <code>vhost</code> is the virtual interface and <code>vhost0.10</code> is the <code>vlan 10</code> tagged version. The post up arguments delete the default lan route for my <code>lan1</code> interface and replace it with one that has <code>metric 1</code>, so the <code>vhost</code> route for the lan is preferred.</p> <p>You'll notice that I'm using <code>lan1</code> for my main physical interface instead of the detected <code>enp4s0</code>. That's because the auto generated name is based on the pci bus and slot ids and unfortunately not static. When I plug and unplug my coral into the pci-e slot, the interface name flip flops between <code>enp3s0</code> and <code>enp4s0</code>, which is far from ideal when linking virtual interfaces, using static IP rules, and customizing routes.</p> <p>So I had to resort to creating a permanent name for my main physical interface via a udev rule that matches the name to the interface's MAC address. I created a file at <code>/etc/udev/rules.d/10-custom-lan1.rules</code> with the following content: <pre><code>SUBSYSTEM==\"net\", ACTION==\"add\", DRIVERS==\"?*\",\nATTR{address}==\"&lt;my MAC address&gt;\", NAME=\"lan1\"\n</code></pre> So now my main physical interface is listed as <code>lan1</code>, with the non-permanent name listed as <code>altname enp4s0</code>.</p> <p>When I create a macvlan network in docker, I use the parent <code>vhost0</code> or <code>vhost0.10</code> as appropriate.</p> <pre><code>networks:\n  macvlan:\n    name: macvlan\n    driver: macvlan\n    driver_opts:\n      parent: vhost0\n    ipam:\n      driver: default\n      config:\n       - subnet: 192.168.1.0/24\n         gateway: 192.168.1.1\n  macvlan.10:\n    name: macvlan.10\n    driver: macvlan\n    driver_opts:\n      parent: vhost0.10\n    ipam:\n      driver: default\n      config:\n       - subnet: 192.168.2.0/24\n         gateway: 192.168.2.1\n</code></pre>","tags":["Other"]},{"location":"Other/zfshost/#immich-stack","title":"Immich Stack","text":"<p>Immich set up involves a stack of 4 containers. I elected to keep it in a separate yaml because updates require comparing the yaml contents to the upstream's recommended yaml (that gets updated with each upstream release) and carefully editing/updating pinned image tags and other arguments.</p> <p>Disclaimer: I'm pretty anal retentive about my family photos. I need to keep original copies of photos backed up both locally and remotely and can't stand the idea of losing photos. Perhaps my descendants (if any are into history or are sentimental) will thank me for it, who knows. . .</p> <p>Prior to setting up Immich, I would manually transfer photos from the family cell phones to my server via smb. That way I kept a master record of all family photos that would get backed up to Backblaze B2 weekly. But as with any manual operation, the frequency of transfers was not great and I risked losing data between transfers. In fact, I noticed that some photos got corrupted on the device some days or weeks after they were taken (I know they werent't initially corrupt because they were uploaded to Google Photos properly shortly after they were taken). Somehow between the photos being taken (and subsequently uploaded Google) and my manual transfer, something accessed the photos on the device and corrupted them. No idea what, but I wanted to prevent that in the future.</p> <p>When I set up Immich (as a backup to Google Photos because there is always the possibility of Google making a change that would make it unfeasible for me to continue using it), I wanted to make sure Immich only had read only access to my photos (since it's still considered alpha software and has breaking changes). I added my photos library to Immich as an external library and mounted the path in the Immich container as read-only. For uploads, I set up Nextcloud, which the phones would upload to Nextcloud automatically, and a nightly cron script would copy the photos to my photos library, which Immich would scan and detect shortly after.</p> <p>Unfortunately Nextcloud's photo sync function turned out to be unreliable. First I noticed it was stripping geotags from photos when uploading because it needed a special Android permission. After assigning that permission, it worked for a couple of months but then broke again. Apparently Google blocked Nextcloud from accessing that permission. That became a deal breaker for me and I had to migrate. It also had other bugs like trying to upload temp files (hidden, starting with a period in their name) and sometimes succeeding but often failing with errors (I don't know which is worse), even though the option in settings to ignore hidden files was checked. The bug report pending 5 months with no team response (other than adding a couple of tags) and reddit posts about the issue going back much longer.</p> <p>Hesitantly, I switched to using Immich's Android app to upload photos, which meant that Immich would have write access to all my photos going forward. The compromise I came up with is letting Immich upload to its internal library, then a nightly cron script copies the newly added photos to a separate folder, which I use for long term storage and back up to Backblaze from. So if Immich does something unexpected or unwanted to the photos in the future, I would still have untouched copies in that other folder. Sure, if Immich messes with the photos right after upload and before the nightly cron copy, I'm out of luck, but it's a fairly small risk. I'm more worried about a potential Immich bug that would mass modify older photos, in which case I would be protected.</p> <p>To sum up, I have the following folders on the server: - <code>/mnt/user/Pictures/All</code>: contains all original photos taken priot to starting with Immich. Backed up weekly to Backblaze B2 - <code>/mnt/user/Pictures/All-Immich</code>: contains all original photos uploaded by Immich and copied here nightly. Backed up weekly to Backblaze B2 - <code>/mnt/user/Immich</code>: Immich's internal library. All mobile uploaded photos go here.</p> <p>As you can see there is duplication between the last two paths as the nightly cron script copies photos from one folder to the other. To prevent using double the storage space, I could use hardlinks, but that would mean Immich making changes to one copy would also modify the other copy and that would defeat the purpose. I'm currently looking into ZFS deduplication feature. In the past it was highly recommended against due to really high resource utilization. But ZFS 2.3 apparently introduced a <code>fast dedup</code> feature (rather a collection of features and improvements) that reduces the resource utilization and makes the feature more useful. ZFS dedup works at a block level and would prevent double storage fo copied files in different folders. It would also simply duplicate the blocks if Immich ever made a change to its own copy so the copied version remains untouched. I'll have to do some tests before jumping onto it. Debian backports just got support for ZFS 2.3.0 (as of 2025-03-20) so it's brand new.</p>","tags":["Other"]},{"location":"Other/zfshost/#vms","title":"VMs","text":"<p>I was quite spoiled by Unraid's VM management interface, which was pretty good. I mainly used two VMs: - Win11 VM for a dual purpose:   - Adobe Suite (I don't want to install any Adobe stuff on my main computer because Creative Cloud spreads like a virus with its million background processes that are impossible to disable as it turns into a game of whack-a-mole)   - Bypassing VPN (my entire internet connection goes over Torguard via Wireguard tunnels for privacy but some websites block me. In those crucial cases, I use the browser of the VM, which bypasses the VPN via firewall rules, which is much easier than modifying firewall rules for my main computer whenever I need to access such a website). - Hackintosh VM specifically for tracking Airtags that I put in various bags. Apparently you can only track Airtags via an Apple device and not on the web (through iCloud). Thankfully a hackintosh VM counts as an Apple device.</p> <p>I was really dreading migrating them and using cli kvm tools to manage them. But I found out about Cockpit which made it pretty easy to move the VMs over and manage them. Its gui even has a built-in VNC viewer. For the Hackintosh VM I had to manually edit the xml for a couple of things but most other things I could do from the gui. It was as simple as moving the VM disk files over to the new server and importing them while selecting the necessary info like cpu and network devices.</p> <p>When I need to fire up one of the VMs I just do it from the Cockpit interface. Bonus: It also has a pretty good ZFS module for viewing various stats about storage and snapshots and all that.</p>","tags":["Other"]}]}